{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "employed-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import col, substring\n",
    "\n",
    "# for creating pipelines and model\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "precise-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n",
    "from time import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars xgboost4j-0.90.jar,xgboost4j-spark-0.90.jar pyspark-shell'\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-discovery",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "+---------+------+---+\n",
      "|machineID| model|age|\n",
      "+---------+------+---+\n",
      "|        1|model3| 18|\n",
      "|        2|model4|  7|\n",
      "|        3|model3|  8|\n",
      "|        4|model3|  7|\n",
      "|        5|model3|  2|\n",
      "|        6|model3|  7|\n",
      "|        7|model3| 20|\n",
      "|        8|model3| 16|\n",
      "|        9|model4|  7|\n",
      "|       10|model3| 10|\n",
      "|       11|model2|  6|\n",
      "|       12|model3|  9|\n",
      "|       13|model1| 15|\n",
      "|       14|model3|  1|\n",
      "|       15|model3| 14|\n",
      "|       16|model1|  3|\n",
      "|       17|model1| 14|\n",
      "|       18|model3| 15|\n",
      "|       19|model3| 17|\n",
      "|       20|model2| 16|\n",
      "+---------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"..\\data\\machines.csv\"\n",
    "machines = spark.read.csv(filename, sep=',', header=True)\n",
    "\n",
    "print(machines.count())\n",
    "machines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "disturbed-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731358\n",
      "+-------+------+\n",
      "|label_e| count|\n",
      "+-------+------+\n",
      "|    0.0|681219|\n",
      "|    1.0| 13253|\n",
      "|    4.0| 10352|\n",
      "|    3.0|  7922|\n",
      "|    2.0| 18612|\n",
      "+-------+------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>volt_rollingmean_36</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 07:00:00</td>\n",
       "      <td>166.950543</td>\n",
       "      <td>294.433319</td>\n",
       "      <td>94.473184</td>\n",
       "      <td>49.062098</td>\n",
       "      <td>165.197336</td>\n",
       "      <td>278.987299</td>\n",
       "      <td>97.318305</td>\n",
       "      <td>50.799015</td>\n",
       "      <td>166.522216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-31 19:00:00</td>\n",
       "      <td>165.290113</td>\n",
       "      <td>285.328277</td>\n",
       "      <td>96.147439</td>\n",
       "      <td>51.315016</td>\n",
       "      <td>164.807180</td>\n",
       "      <td>272.786127</td>\n",
       "      <td>99.193202</td>\n",
       "      <td>49.970419</td>\n",
       "      <td>167.168538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-31 07:00:00</td>\n",
       "      <td>164.324247</td>\n",
       "      <td>260.243976</td>\n",
       "      <td>102.238964</td>\n",
       "      <td>48.625823</td>\n",
       "      <td>168.107750</td>\n",
       "      <td>313.399517</td>\n",
       "      <td>102.155735</td>\n",
       "      <td>44.050788</td>\n",
       "      <td>170.913102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-30 19:00:00</td>\n",
       "      <td>171.891253</td>\n",
       "      <td>366.555058</td>\n",
       "      <td>102.072506</td>\n",
       "      <td>39.475754</td>\n",
       "      <td>174.207530</td>\n",
       "      <td>370.407544</td>\n",
       "      <td>101.847041</td>\n",
       "      <td>40.153107</td>\n",
       "      <td>171.536284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-30 07:00:00</td>\n",
       "      <td>176.523807</td>\n",
       "      <td>374.260029</td>\n",
       "      <td>101.621576</td>\n",
       "      <td>40.830461</td>\n",
       "      <td>171.358800</td>\n",
       "      <td>384.893390</td>\n",
       "      <td>98.324312</td>\n",
       "      <td>40.781041</td>\n",
       "      <td>168.852995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-12-29 19:00:00</td>\n",
       "      <td>166.193793</td>\n",
       "      <td>395.526750</td>\n",
       "      <td>95.027049</td>\n",
       "      <td>40.731622</td>\n",
       "      <td>165.017589</td>\n",
       "      <td>430.664022</td>\n",
       "      <td>95.126967</td>\n",
       "      <td>39.955173</td>\n",
       "      <td>166.149802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-12-29 07:00:00</td>\n",
       "      <td>163.841386</td>\n",
       "      <td>465.801294</td>\n",
       "      <td>95.226886</td>\n",
       "      <td>39.178725</td>\n",
       "      <td>166.127807</td>\n",
       "      <td>442.403690</td>\n",
       "      <td>97.266080</td>\n",
       "      <td>40.108095</td>\n",
       "      <td>169.289026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-28 19:00:00</td>\n",
       "      <td>168.414229</td>\n",
       "      <td>419.006087</td>\n",
       "      <td>99.305274</td>\n",
       "      <td>41.037466</td>\n",
       "      <td>172.012846</td>\n",
       "      <td>417.996085</td>\n",
       "      <td>99.676624</td>\n",
       "      <td>40.791599</td>\n",
       "      <td>171.778403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-12-28 07:00:00</td>\n",
       "      <td>175.611464</td>\n",
       "      <td>416.986082</td>\n",
       "      <td>100.047975</td>\n",
       "      <td>40.545732</td>\n",
       "      <td>173.460491</td>\n",
       "      <td>436.441885</td>\n",
       "      <td>100.938148</td>\n",
       "      <td>39.607895</td>\n",
       "      <td>171.000912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-12-27 19:00:00</td>\n",
       "      <td>171.309517</td>\n",
       "      <td>455.897688</td>\n",
       "      <td>101.828321</td>\n",
       "      <td>38.670059</td>\n",
       "      <td>168.695636</td>\n",
       "      <td>456.884537</td>\n",
       "      <td>101.517029</td>\n",
       "      <td>39.079920</td>\n",
       "      <td>167.336487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>model1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0 2016-01-01 07:00:00           166.950543             294.433319   \n",
       "1 2015-12-31 19:00:00           165.290113             285.328277   \n",
       "2 2015-12-31 07:00:00           164.324247             260.243976   \n",
       "3 2015-12-30 19:00:00           171.891253             366.555058   \n",
       "4 2015-12-30 07:00:00           176.523807             374.260029   \n",
       "5 2015-12-29 19:00:00           166.193793             395.526750   \n",
       "6 2015-12-29 07:00:00           163.841386             465.801294   \n",
       "7 2015-12-28 19:00:00           168.414229             419.006087   \n",
       "8 2015-12-28 07:00:00           175.611464             416.986082   \n",
       "9 2015-12-27 19:00:00           171.309517             455.897688   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0                94.473184                 49.062098           165.197336   \n",
       "1                96.147439                 51.315016           164.807180   \n",
       "2               102.238964                 48.625823           168.107750   \n",
       "3               102.072506                 39.475754           174.207530   \n",
       "4               101.621576                 40.830461           171.358800   \n",
       "5                95.027049                 40.731622           165.017589   \n",
       "6                95.226886                 39.178725           166.127807   \n",
       "7                99.305274                 41.037466           172.012846   \n",
       "8               100.047975                 40.545732           173.460491   \n",
       "9               101.828321                 38.670059           168.695636   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             278.987299                97.318305                 50.799015   \n",
       "1             272.786127                99.193202                 49.970419   \n",
       "2             313.399517               102.155735                 44.050788   \n",
       "3             370.407544               101.847041                 40.153107   \n",
       "4             384.893390                98.324312                 40.781041   \n",
       "5             430.664022                95.126967                 39.955173   \n",
       "6             442.403690                97.266080                 40.108095   \n",
       "7             417.996085                99.676624                 40.791599   \n",
       "8             436.441885               100.938148                 39.607895   \n",
       "9             456.884537               101.517029                 39.079920   \n",
       "\n",
       "   volt_rollingmean_36  ...  error5sum_rollingmean_24  comp1sum  comp2sum  \\\n",
       "0           166.522216  ...                       0.0     489.0     549.0   \n",
       "1           167.168538  ...                       0.0     489.0     549.0   \n",
       "2           170.913102  ...                       0.0     488.0     548.0   \n",
       "3           171.536284  ...                       0.0     488.0     548.0   \n",
       "4           168.852995  ...                       0.0     487.0     547.0   \n",
       "5           166.149802  ...                       0.0     487.0     547.0   \n",
       "6           169.289026  ...                       0.0     486.0     546.0   \n",
       "7           171.778403  ...                       0.0     486.0     546.0   \n",
       "8           171.000912  ...                       0.0     485.0     545.0   \n",
       "9           167.336487  ...                       0.0     485.0     545.0   \n",
       "\n",
       "   comp3sum  comp4sum   model   age    model_encoded  failure  label_e  \n",
       "0     549.0     564.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "1     549.0     564.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "2     548.0     563.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "3     548.0     563.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "4     547.0     562.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "5     547.0     562.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "6     546.0     561.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "7     546.0     561.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "8     545.0     560.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "9     545.0     560.0  model1  18.0  (0.0, 0.0, 0.0)      0.0      0.0  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data = spark.read.parquet('../data/labeled_features2.parquet')\n",
    "feat_data = feat_data.withColumn(\"age\", feat_data.age.cast(DoubleType()))\n",
    "\n",
    "print(feat_data.count())\n",
    "# highly imbalanced data\n",
    "print(feat_data.groupby('label_e').count().show())\n",
    "feat_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "australian-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volt_rollingmean_12',\n",
       " 'rotate_rollingmean_12',\n",
       " 'pressure_rollingmean_12',\n",
       " 'vibration_rollingmean_12',\n",
       " 'volt_rollingmean_24',\n",
       " 'rotate_rollingmean_24',\n",
       " 'pressure_rollingmean_24',\n",
       " 'vibration_rollingmean_24',\n",
       " 'volt_rollingmean_36',\n",
       " 'vibration_rollingmean_36',\n",
       " 'rotate_rollingmean_36',\n",
       " 'pressure_rollingmean_36',\n",
       " 'volt_rollingstd_12',\n",
       " 'rotate_rollingstd_12',\n",
       " 'pressure_rollingstd_12',\n",
       " 'vibration_rollingstd_12',\n",
       " 'volt_rollingstd_24',\n",
       " 'rotate_rollingstd_24',\n",
       " 'pressure_rollingstd_24',\n",
       " 'vibration_rollingstd_24',\n",
       " 'volt_rollingstd_36',\n",
       " 'rotate_rollingstd_36',\n",
       " 'pressure_rollingstd_36',\n",
       " 'vibration_rollingstd_36',\n",
       " 'error1sum_rollingmean_24',\n",
       " 'error2sum_rollingmean_24',\n",
       " 'error3sum_rollingmean_24',\n",
       " 'error4sum_rollingmean_24',\n",
       " 'error5sum_rollingmean_24',\n",
       " 'comp1sum',\n",
       " 'comp2sum',\n",
       " 'comp3sum',\n",
       " 'comp4sum',\n",
       " 'age']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_var = ['label_e']\n",
    "key_cols =['machineID','dt_truncated']\n",
    "input_features = feat_data.columns\n",
    "remove_cols = label_var + key_cols + ['failure','model_encoded','model' ]\n",
    "\n",
    "# Remove the extra names if that are in the input_features list\n",
    "input_features = [x for x in input_features if x not in set(remove_cols)]\n",
    "# Use cols\n",
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "annoying-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60434\n",
      "12708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>label_e</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-29 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.86062995243768, 465.7109861176555, 100.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-29 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.43198744206904, 448.0433348558192, 101.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-28 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.2757748421423, 458.4032239664128, 100.959...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-28 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.01721800874137, 467.8743692043002, 102.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-27 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[168.3327611402693, 453.6379502402023, 100.021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-27 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[171.56623565255208, 444.39648803834757, 97.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-26 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.81793567322822, 465.53779019493817, 95.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-26 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.12255821618726, 461.86202666105595, 99.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-25 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[173.10494998081575, 460.7332071745943, 98.740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-25 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.73200216875014, 459.76336625659087, 99.14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  machineID        dt_truncated  label_e  \\\n",
       "0        60 2015-10-29 20:00:00      0.0   \n",
       "1        60 2015-10-29 08:00:00      0.0   \n",
       "2        60 2015-10-28 20:00:00      0.0   \n",
       "3        60 2015-10-28 08:00:00      0.0   \n",
       "4        60 2015-10-27 20:00:00      0.0   \n",
       "5        60 2015-10-27 08:00:00      0.0   \n",
       "6        60 2015-10-26 20:00:00      0.0   \n",
       "7        60 2015-10-26 08:00:00      0.0   \n",
       "8        60 2015-10-25 20:00:00      0.0   \n",
       "9        60 2015-10-25 08:00:00      0.0   \n",
       "\n",
       "                                            features  \n",
       "0  [169.86062995243768, 465.7109861176555, 100.12...  \n",
       "1  [166.43198744206904, 448.0433348558192, 101.67...  \n",
       "2  [169.2757748421423, 458.4032239664128, 100.959...  \n",
       "3  [169.01721800874137, 467.8743692043002, 102.92...  \n",
       "4  [168.3327611402693, 453.6379502402023, 100.021...  \n",
       "5  [171.56623565255208, 444.39648803834757, 97.59...  \n",
       "6  [166.81793567322822, 465.53779019493817, 95.72...  \n",
       "7  [166.12255821618726, 461.86202666105595, 99.17...  \n",
       "8  [173.10494998081575, 460.7332071745943, 98.740...  \n",
       "9  [166.73200216875014, 459.76336625659087, 99.14...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble features\n",
    "va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "feat_data = va.transform(feat_data).select('machineID','dt_truncated','label_e','features')\n",
    "\n",
    "# set maxCategories so features with > 10 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=10).fit(feat_data)\n",
    "\n",
    "# fit on whole dataset to include all labels in index\n",
    "labelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(feat_data)\n",
    "\n",
    "# split the data into train/test based on date\n",
    "split_date = \"2015-10-30\"\n",
    "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
    "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
    "\n",
    "print(training.count())\n",
    "print(testing.count())\n",
    "training.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample majority class, do we really need this?\n",
    "# SampleBy returns a stratified sample without replacement based on the fraction given on each stratum\n",
    "train_downsampled = training.sampleBy('label', fractions={0.0: 0.135, 1.0: 1.0}, seed=123).cache()\n",
    "train_downsampled.groupby('label').count().show()\n",
    "\n",
    "testing.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache results\n",
    "# cache datasets in memory\n",
    "train_downsampled.cache()\n",
    "testing.cache()\n",
    "\n",
    "# check the number of devices in training and testing data\n",
    "print(train_downsampled.select('deviceid').distinct().count())\n",
    "print(testing.select('deviceid').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-forward",
   "metadata": {},
   "source": [
    "# GBT Gradient-Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pursuant-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machineID', 'string'),\n",
       " ('dt_truncated', 'timestamp'),\n",
       " ('label_e', 'double'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBTClassifier currently only supports binary classification.\n",
    "training.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol='label_e', featuresCol='features', maxDepth=10, minInstancesPerNode=5, maxIter=50)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline_gbt = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model. This also runs the indexers.\n",
    "model_gbt = pipeline_gbt.fit(training)\n",
    "\n",
    "# save model\n",
    "datestamp = unicode(datetime.datetime.now()).replace(' ','').replace(':','_');\n",
    "gbt_fileName = '../checkpoints/GradientBoostedTree_' + datestamp;\n",
    "gbtDirfilename = modelDir + gbt_fileName;\n",
    "model_gbt.save(gbtDirfilename)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_gbt = model_gbt.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-gasoline",
   "metadata": {},
   "source": [
    "# XGB eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://repo1.maven.org/maven2/com/nvidia/xgboost4j_3.0/1.0.0-0.1.0/xgboost4j_3.0-1.0.0-0.1.0.jar\n",
    "#!wget https://repo1.maven.org/maven2/com/nvidia/xgboost4j-spark_3.0/1.0.0-0.1.0/xgboost4j-spark_3.0-1.0.0-0.1.0.jar\n",
    "#!wget http://insecure.repo1.maven.org/maven2/com/nvidia/rapids-4-spark_2.12/0.1.0/rapids-4-spark_2.12-0.1.0.jar\n",
    "#!wget https://repo1.maven.org/maven2/ai/rapids/cudf/0.18/cudf-0.18-cuda10-1.jar --no-check-certificate\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/srivatsan88/YoutubeLI/master/dataset/covtype_train.parquet\n",
    "#!wget https://raw.githubusercontent.com/srivatsan88/YoutubeLI/master/dataset/covtype_test.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compliant-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"xgboost4j-spark_3.0-1.0.0-0.1.0.jar\")\n",
    "spark.sparkContext.addPyFile(\"rapids-4-spark_2.12-0.1.0.jar\")\n",
    "\n",
    "from ml.dmlc.xgboost4j.scala.spark import XGBoostClassificationModel, XGBoostClassifier\n",
    "#training.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "palestinian-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoostClassifier_6d72fffbfc9d"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting parameters. you can find these parameters in the link above.\n",
    "params = {'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "          'treeMethod': 'gpu_hist', 'maxDepth': 3, \n",
    "          'growPolicy': 'depthwise', 'lambda_': 1.0,\n",
    "          'subsample': 1.0, 'numRound': 1000,\n",
    "          'numWorkers': 1, 'verbosity': 1}\n",
    "\n",
    "features = [feat for feat in feat_data.columns if feat != 'label_e']\n",
    "\n",
    "# create XGBoost model object\n",
    "# xgboost = XGBoostClassifier()\\\n",
    "#             .setLabelCol('label_e')\\\n",
    "#             .setFeaturesCols(features)\n",
    "\n",
    "xgboost = XGBoostClassifier(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label_e\", \n",
    ")\n",
    "xgboost.setMissing(0.0)\n",
    "\n",
    "# # getting the feature names\n",
    "# target = 'label_e'\n",
    "# features = [feat for feat in feat_data.columns if feat != target]\n",
    "\n",
    "# # setting parameters. you can find these parameters in the link above.\n",
    "# params = {'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "#           'treeMethod': 'gpu_hist', 'maxDepth': 3, \n",
    "#           'growPolicy': 'depthwise', 'lambda_': 1.0,\n",
    "#           'subsample': 1.0, 'numRound': 1000,\n",
    "#           'numWorkers': 1, 'verbosity': 1}\n",
    "\n",
    "# # create XGBoost model object\n",
    "# xgboost = XGBoostClassifier(**params)\\\n",
    "#             .setLabelCol(target)\\\n",
    "#             .setFeaturesCols(features)\n",
    "\n",
    "# xgboost.setMaxDepth(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = xgboost.fit(training)\n",
    "\n",
    "print(\"Training Time: %s seconds\" % (str(time.time() - start_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-modern",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"xgboost4j-spark-0.90.jar\")\n",
    "spark.sparkContext.addPyFile(\"sparkxgb.zip\")\n",
    "\n",
    "from sparkxgb import XGBoostClassifier\n",
    "\n",
    "\n",
    "# loading data\n",
    "reader = spark.read\n",
    "train_data = reader.parquet(\"covtype_train.parquet\")\n",
    "test_data = reader.parquet(\"covtype_test.parquet\")\n",
    "\n",
    "# getting the feature names\n",
    "target = 'target'\n",
    "features = [feat for feat in train_data.schema.names if feat != target]\n",
    "\n",
    "# CPU\n",
    "def vectorize(data_frame):\n",
    "    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\n",
    "    return (VectorAssembler()\n",
    "        .setInputCols(features)\n",
    "        .setOutputCol('features')\n",
    "        .transform(data_frame.select(to_floats))\n",
    "        .select(col('features'), col('target')))\n",
    "\n",
    "train_data = vectorize(train_data)\n",
    "\n",
    "# setting parameters. you can find these parameters in the link above.\n",
    "params = { \n",
    "    'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "    'treeMethod': 'hist', 'maxDepth': 10, \n",
    "    'maxLeaves': 256, 'growPolicy': 'depthwise',\n",
    "    'minChildWeight': 30.0, 'lambda_': 1.0,\n",
    "    'scalePosWeight': 2.0, 'subsample': 1.0,\n",
    "    'nthread': 1, 'numWorkers': 1,\n",
    "}\n",
    "\n",
    "# create XGBoost model object\n",
    "xgboost = XGBoostClassifier(**params)\\\n",
    "            .setLabelCol('target')\\\n",
    "            .setFeaturesCol('features')\n",
    "train_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thousand-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "\n",
    "# loading data\n",
    "reader = spark.read\n",
    "train_data = reader.parquet(\"covtype_train.parquet\")\n",
    "test_data = reader.parquet(\"covtype_test.parquet\")\n",
    "\n",
    "# getting the feature names\n",
    "target = 'target'\n",
    "features = [feat for feat in train_data.schema.names if feat != target]\n",
    "\n",
    "# CPU\n",
    "def vectorize(data_frame):\n",
    "    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\n",
    "    return (VectorAssembler()\n",
    "        .setInputCols(features)\n",
    "        .setOutputCol('features')\n",
    "        .transform(data_frame.select(to_floats))\n",
    "        .select(col('features'), col('target')))\n",
    "\n",
    "\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3, n_estimators=100,\n",
    "                            objective='binary:logistic', booster='gbtree',\n",
    "                            n_jobs=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Values:  [0.74 0.75]\n",
      "Average Accuracy:  0.7448269185258493\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "#model = xgboost.fit(train_data)\n",
    "data = train_data.toPandas()\n",
    "X = data.iloc[:,:-1] # Feature matrix in pd.DataFrame format\n",
    "y = data.iloc[:,-1] # Target vector in pd.Series format\n",
    "\n",
    "acc_scores = cross_val_score(xgb_clf, X, y,\n",
    "                         scoring=\"accuracy\",\n",
    "                         cv=2, n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy Values: \", np.round(acc_scores, 2))\n",
    "print(\"Average Accuracy: \", np.mean(acc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-combination",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "found-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1| 11062|\n",
      "|    3|  6577|\n",
      "|    4|  8617|\n",
      "|    2| 15523|\n",
      "|    0|112363|\n",
      "+-----+------+\n",
      "\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|  2191|\n",
      "|    3|  1345|\n",
      "|    4|  1735|\n",
      "|    2|  3089|\n",
      "|    0|118691|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, plot_roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "split_date = \"2015-10-30\"\n",
    "feat_data = feat_data.withColumnRenamed(\"label_e\", \"label\")\n",
    "feat_data = feat_data.withColumn(\"machineID\", feat_data.machineID.cast(IntegerType()))\n",
    "feat_data = feat_data.withColumn(\"label\", feat_data.label.cast(IntegerType()))\n",
    "feat_data = feat_data.withColumn(\"model\", substring(\"model\", 6,1).cast(IntegerType()))\n",
    "\n",
    "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
    "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
    "train_data = training.drop(*['dt_truncated', 'model_encoded']) #model???\n",
    "test_data = testing.drop(*['dt_truncated', 'model_encoded'])\n",
    "\n",
    "train_data = train_data.sampleBy('label', fractions={0: 0.2, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}, seed=0).cache()\n",
    "train_data.groupby('label').count().show()\n",
    "test_data.groupby('label').count().show()\n",
    "\n",
    "# train_data.dtypes\n",
    "# print(train_data.count())\n",
    "# print(test_data.count())\n",
    "# train_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ignored-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train_data.toPandas()\n",
    "test_ = test_data.toPandas()\n",
    "\n",
    "X_train = train_.iloc[:,:-1]\n",
    "y_train = train_.iloc[:,-1]\n",
    "X_test = test_.iloc[:,:-1]\n",
    "y_test = test_.iloc[:,-1]\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=50, n_estimators=500, grow_policy='lossguide',\n",
    "                            objective='multi:softmax', booster='gbtree', num_classes=5,\n",
    "                            eta=0.2, reg_lambda=1.0, n_jobs=2, random_state=1)\n",
    "\n",
    "model = xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alleged-panic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.951\n"
     ]
    }
   ],
   "source": [
    "# preds = xgb_clf.predict(dtest)\n",
    "# Predictions returns as probabilities\n",
    "# y_pred = [round(value) for value in preds]\n",
    "# Predictions returns as classes\n",
    "# y_pred = np.array(y_pred).astype(int) \n",
    "y_pred = model.predict(X_test) \n",
    "y_true = y_test # True values, dataframe format\n",
    "\n",
    "print(\"Accuracy: \", np.round(accuracy_score(y_true, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conditional-small",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|    4|         2|    18|\n",
      "|    3|         3|   800|\n",
      "|    3|         1|     6|\n",
      "|    4|         3|    23|\n",
      "|    2|         4|     7|\n",
      "|    1|         0|   988|\n",
      "|    3|         4|     6|\n",
      "|    2|         3|     8|\n",
      "|    3|         2|    24|\n",
      "|    4|         0|   629|\n",
      "|    2|         2|  1803|\n",
      "|    1|         3|     2|\n",
      "|    3|         0|   509|\n",
      "|    2|         0|  1261|\n",
      "|    0|         1|  1044|\n",
      "|    0|         2|  1104|\n",
      "|    0|         0|115936|\n",
      "|    2|         1|    10|\n",
      "|    1|         1|  1184|\n",
      "|    0|         3|   217|\n",
      "+-----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = y_pred.tolist()\n",
    "prediction = testing.repartition(1).withColumn('prediction', \n",
    "    F.udf(lambda x: l[x])(F.monotonically_increasing_id()))\n",
    "prediction.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hispanic-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 37.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter:  {'subsample': 1.0000000000000004, 'reg_lambda': 0.7, 'objective': 'multi:softmax', 'num_classes': 5, 'n_estimators': 150, 'max_depth': 70, 'learning_rate': 0.45, 'grow_policy': 'depthwise', 'booster': 'gbtree'}\n",
      "Best score:  0.7009684474258915\n"
     ]
    }
   ],
   "source": [
    "train_ = train_data.toPandas()\n",
    "test_ = test_data.toPandas()\n",
    "\n",
    "X_train = train_.iloc[:,:-1]\n",
    "y_train = train_.iloc[:,-1]\n",
    "X_test = test_.iloc[:,:-1]\n",
    "y_test = test_.iloc[:,-1]\n",
    "\n",
    "param_dict = {'learning_rate': np.arange(0.0, 0.55, 0.025),\n",
    "              'max_depth': np.arange(20, 105, 10),\n",
    "              'n_estimators': [50, 100, 150, 200],\n",
    "              'grow_policy':['depthwise', 'lossguide'],\n",
    "              'objective': ['multi:softmax'],\n",
    "              'booster': ['gbtree'],\n",
    "              'num_classes': [5],\n",
    "              'subsample': np.arange(0.8, 1.05, 0.05),\n",
    "              'reg_lambda': np.arange(0.5, 2.05, 0.1)}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "# scoring = 'recall_micro'\n",
    "# scoring = 'balanced_accuracy'\n",
    "# scoring = 'average_precision'\n",
    "# scoring = 'roc_auc_ovo'\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=0)\n",
    "clf_random = RandomizedSearchCV(estimator = xgb_clf, param_distributions = param_dict, \n",
    "                                n_iter = 40, scoring = 'f1_macro', cv = cv,\n",
    "                                n_jobs = 4, random_state = 0, verbose = 1)\n",
    "\n",
    "clf_random.fit(X_train, y_train)\n",
    "model = clf_random.best_estimator_\n",
    "print(\"Best parameter: \", clf_random.best_params_)\n",
    "print(\"Best score: \", clf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
