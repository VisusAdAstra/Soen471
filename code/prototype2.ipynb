{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, FloatType, IntegerType\n",
    "from pyspark.sql.functions import col, substring\n",
    "\n",
    "# for creating pipelines and model\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precise-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n",
    "from time import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars xgboost4j-0.90.jar,xgboost4j-spark-0.90.jar pyspark-shell'\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-discovery",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mathematical-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "+---------+------+---+\n",
      "|machineID| model|age|\n",
      "+---------+------+---+\n",
      "|        1|model3| 18|\n",
      "|        2|model4|  7|\n",
      "|        3|model3|  8|\n",
      "|        4|model3|  7|\n",
      "|        5|model3|  2|\n",
      "|        6|model3|  7|\n",
      "|        7|model3| 20|\n",
      "|        8|model3| 16|\n",
      "|        9|model4|  7|\n",
      "|       10|model3| 10|\n",
      "|       11|model2|  6|\n",
      "|       12|model3|  9|\n",
      "|       13|model1| 15|\n",
      "|       14|model3|  1|\n",
      "|       15|model3| 14|\n",
      "|       16|model1|  3|\n",
      "|       17|model1| 14|\n",
      "|       18|model3| 15|\n",
      "|       19|model3| 17|\n",
      "|       20|model2| 16|\n",
      "+---------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"..\\data\\machines.csv\"\n",
    "machines = spark.read.csv(filename, sep=',', header=True)\n",
    "\n",
    "print(machines.count())\n",
    "machines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disturbed-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73142\n",
      "+-------+-----+\n",
      "|label_e|count|\n",
      "+-------+-----+\n",
      "|    0.0|67470|\n",
      "|    1.0| 1337|\n",
      "|    4.0| 1473|\n",
      "|    3.0| 1000|\n",
      "|    2.0| 1862|\n",
      "+-------+-----+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>volt_rollingmean_36</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 07:00:00</td>\n",
       "      <td>172.083928</td>\n",
       "      <td>453.576897</td>\n",
       "      <td>101.303110</td>\n",
       "      <td>40.627410</td>\n",
       "      <td>169.230878</td>\n",
       "      <td>451.007306</td>\n",
       "      <td>100.487259</td>\n",
       "      <td>40.839262</td>\n",
       "      <td>167.339602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-31 19:00:00</td>\n",
       "      <td>168.173348</td>\n",
       "      <td>453.181951</td>\n",
       "      <td>99.527531</td>\n",
       "      <td>40.981132</td>\n",
       "      <td>165.787189</td>\n",
       "      <td>449.842118</td>\n",
       "      <td>100.598808</td>\n",
       "      <td>41.791947</td>\n",
       "      <td>166.190766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-31 07:00:00</td>\n",
       "      <td>163.401030</td>\n",
       "      <td>446.502286</td>\n",
       "      <td>101.670084</td>\n",
       "      <td>42.602762</td>\n",
       "      <td>165.199475</td>\n",
       "      <td>445.038344</td>\n",
       "      <td>101.074817</td>\n",
       "      <td>41.722713</td>\n",
       "      <td>168.995817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-30 19:00:00</td>\n",
       "      <td>166.997919</td>\n",
       "      <td>443.574402</td>\n",
       "      <td>100.479550</td>\n",
       "      <td>40.842664</td>\n",
       "      <td>171.793211</td>\n",
       "      <td>450.456864</td>\n",
       "      <td>100.955598</td>\n",
       "      <td>40.418503</td>\n",
       "      <td>172.419415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-30 07:00:00</td>\n",
       "      <td>176.588502</td>\n",
       "      <td>457.339327</td>\n",
       "      <td>101.431647</td>\n",
       "      <td>39.994342</td>\n",
       "      <td>175.130162</td>\n",
       "      <td>466.483595</td>\n",
       "      <td>99.468624</td>\n",
       "      <td>40.920312</td>\n",
       "      <td>174.914358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-12-29 19:00:00</td>\n",
       "      <td>173.671822</td>\n",
       "      <td>475.627863</td>\n",
       "      <td>97.505602</td>\n",
       "      <td>41.846282</td>\n",
       "      <td>174.077285</td>\n",
       "      <td>464.681249</td>\n",
       "      <td>99.852795</td>\n",
       "      <td>41.520096</td>\n",
       "      <td>173.561514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-12-29 07:00:00</td>\n",
       "      <td>174.482749</td>\n",
       "      <td>453.734636</td>\n",
       "      <td>102.199989</td>\n",
       "      <td>41.193909</td>\n",
       "      <td>173.506360</td>\n",
       "      <td>450.268077</td>\n",
       "      <td>101.890206</td>\n",
       "      <td>39.760938</td>\n",
       "      <td>173.318924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-12-28 19:00:00</td>\n",
       "      <td>172.529971</td>\n",
       "      <td>446.801518</td>\n",
       "      <td>101.580424</td>\n",
       "      <td>38.327966</td>\n",
       "      <td>172.737011</td>\n",
       "      <td>443.114257</td>\n",
       "      <td>99.159233</td>\n",
       "      <td>38.946824</td>\n",
       "      <td>171.416655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-12-28 07:00:00</td>\n",
       "      <td>172.944052</td>\n",
       "      <td>439.426996</td>\n",
       "      <td>96.738042</td>\n",
       "      <td>39.565681</td>\n",
       "      <td>170.859997</td>\n",
       "      <td>444.430674</td>\n",
       "      <td>99.034004</td>\n",
       "      <td>39.874349</td>\n",
       "      <td>172.384220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-12-27 19:00:00</td>\n",
       "      <td>168.775941</td>\n",
       "      <td>449.434352</td>\n",
       "      <td>101.329965</td>\n",
       "      <td>40.183016</td>\n",
       "      <td>172.104304</td>\n",
       "      <td>444.571586</td>\n",
       "      <td>98.413556</td>\n",
       "      <td>39.550401</td>\n",
       "      <td>170.807337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>model4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0 2016-01-01 07:00:00           172.083928             453.576897   \n",
       "1 2015-12-31 19:00:00           168.173348             453.181951   \n",
       "2 2015-12-31 07:00:00           163.401030             446.502286   \n",
       "3 2015-12-30 19:00:00           166.997919             443.574402   \n",
       "4 2015-12-30 07:00:00           176.588502             457.339327   \n",
       "5 2015-12-29 19:00:00           173.671822             475.627863   \n",
       "6 2015-12-29 07:00:00           174.482749             453.734636   \n",
       "7 2015-12-28 19:00:00           172.529971             446.801518   \n",
       "8 2015-12-28 07:00:00           172.944052             439.426996   \n",
       "9 2015-12-27 19:00:00           168.775941             449.434352   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               101.303110                 40.627410           169.230878   \n",
       "1                99.527531                 40.981132           165.787189   \n",
       "2               101.670084                 42.602762           165.199475   \n",
       "3               100.479550                 40.842664           171.793211   \n",
       "4               101.431647                 39.994342           175.130162   \n",
       "5                97.505602                 41.846282           174.077285   \n",
       "6               102.199989                 41.193909           173.506360   \n",
       "7               101.580424                 38.327966           172.737011   \n",
       "8                96.738042                 39.565681           170.859997   \n",
       "9               101.329965                 40.183016           172.104304   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             451.007306               100.487259                 40.839262   \n",
       "1             449.842118               100.598808                 41.791947   \n",
       "2             445.038344               101.074817                 41.722713   \n",
       "3             450.456864               100.955598                 40.418503   \n",
       "4             466.483595                99.468624                 40.920312   \n",
       "5             464.681249                99.852795                 41.520096   \n",
       "6             450.268077               101.890206                 39.760938   \n",
       "7             443.114257                99.159233                 38.946824   \n",
       "8             444.430674                99.034004                 39.874349   \n",
       "9             444.571586                98.413556                 39.550401   \n",
       "\n",
       "   volt_rollingmean_36  ...  error5sum_rollingmean_24  comp1sum  comp2sum  \\\n",
       "0           167.339602  ...                       0.0     579.0     534.0   \n",
       "1           166.190766  ...                       0.0     578.0     533.0   \n",
       "2           168.995817  ...                       0.0     578.0     533.0   \n",
       "3           172.419415  ...                       0.0     577.0     532.0   \n",
       "4           174.914358  ...                       0.0     577.0     532.0   \n",
       "5           173.561514  ...                       0.0     576.0     531.0   \n",
       "6           173.318924  ...                       0.0     576.0     531.0   \n",
       "7           171.416655  ...                       0.0     575.0     530.0   \n",
       "8           172.384220  ...                       0.0     575.0     530.0   \n",
       "9           170.807337  ...                       0.0     574.0     529.0   \n",
       "\n",
       "   comp3sum  comp4sum   model  age    model_encoded  failure  label_e  \n",
       "0     474.0     459.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "1     473.0     458.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "2     473.0     458.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "3     472.0     457.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "4     472.0     457.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "5     471.0     456.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "6     471.0     456.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "7     470.0     455.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "8     470.0     455.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "9     469.0     454.0  model4  3.0  (0.0, 1.0, 0.0)      0.0      0.0  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data = spark.read.parquet('../data/labeled_features.parquet')\n",
    "feat_data = feat_data.withColumn(\"age\", feat_data.age.cast(DoubleType()))\n",
    "\n",
    "print(feat_data.count())\n",
    "# highly imbalanced data\n",
    "print(feat_data.groupby('label_e').count().show())\n",
    "feat_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "australian-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volt_rollingmean_12',\n",
       " 'rotate_rollingmean_12',\n",
       " 'pressure_rollingmean_12',\n",
       " 'vibration_rollingmean_12',\n",
       " 'volt_rollingmean_24',\n",
       " 'rotate_rollingmean_24',\n",
       " 'pressure_rollingmean_24',\n",
       " 'vibration_rollingmean_24',\n",
       " 'volt_rollingmean_36',\n",
       " 'vibration_rollingmean_36',\n",
       " 'rotate_rollingmean_36',\n",
       " 'pressure_rollingmean_36',\n",
       " 'volt_rollingstd_12',\n",
       " 'rotate_rollingstd_12',\n",
       " 'pressure_rollingstd_12',\n",
       " 'vibration_rollingstd_12',\n",
       " 'volt_rollingstd_24',\n",
       " 'rotate_rollingstd_24',\n",
       " 'pressure_rollingstd_24',\n",
       " 'vibration_rollingstd_24',\n",
       " 'volt_rollingstd_36',\n",
       " 'rotate_rollingstd_36',\n",
       " 'pressure_rollingstd_36',\n",
       " 'vibration_rollingstd_36',\n",
       " 'error1sum_rollingmean_24',\n",
       " 'error2sum_rollingmean_24',\n",
       " 'error3sum_rollingmean_24',\n",
       " 'error4sum_rollingmean_24',\n",
       " 'error5sum_rollingmean_24',\n",
       " 'comp1sum',\n",
       " 'comp2sum',\n",
       " 'comp3sum',\n",
       " 'comp4sum',\n",
       " 'age']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_var = ['label_e']\n",
    "key_cols =['machineID','dt_truncated']\n",
    "input_features = feat_data.columns\n",
    "remove_cols = label_var + key_cols + ['failure','model_encoded','model' ]\n",
    "\n",
    "# Remove the extra names if that are in the input_features list\n",
    "input_features = [x for x in input_features if x not in set(remove_cols)]\n",
    "# Use cols\n",
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "annoying-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60434\n",
      "12708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>label_e</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-29 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.86062995243768, 465.7109861176555, 100.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-29 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.43198744206904, 448.0433348558192, 101.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-28 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.2757748421423, 458.4032239664128, 100.959...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-28 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[169.01721800874137, 467.8743692043002, 102.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-27 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[168.3327611402693, 453.6379502402023, 100.021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-27 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[171.56623565255208, 444.39648803834757, 97.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-26 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.81793567322822, 465.53779019493817, 95.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-26 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.12255821618726, 461.86202666105595, 99.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-25 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[173.10494998081575, 460.7332071745943, 98.740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>2015-10-25 08:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[166.73200216875014, 459.76336625659087, 99.14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  machineID        dt_truncated  label_e  \\\n",
       "0        60 2015-10-29 20:00:00      0.0   \n",
       "1        60 2015-10-29 08:00:00      0.0   \n",
       "2        60 2015-10-28 20:00:00      0.0   \n",
       "3        60 2015-10-28 08:00:00      0.0   \n",
       "4        60 2015-10-27 20:00:00      0.0   \n",
       "5        60 2015-10-27 08:00:00      0.0   \n",
       "6        60 2015-10-26 20:00:00      0.0   \n",
       "7        60 2015-10-26 08:00:00      0.0   \n",
       "8        60 2015-10-25 20:00:00      0.0   \n",
       "9        60 2015-10-25 08:00:00      0.0   \n",
       "\n",
       "                                            features  \n",
       "0  [169.86062995243768, 465.7109861176555, 100.12...  \n",
       "1  [166.43198744206904, 448.0433348558192, 101.67...  \n",
       "2  [169.2757748421423, 458.4032239664128, 100.959...  \n",
       "3  [169.01721800874137, 467.8743692043002, 102.92...  \n",
       "4  [168.3327611402693, 453.6379502402023, 100.021...  \n",
       "5  [171.56623565255208, 444.39648803834757, 97.59...  \n",
       "6  [166.81793567322822, 465.53779019493817, 95.72...  \n",
       "7  [166.12255821618726, 461.86202666105595, 99.17...  \n",
       "8  [173.10494998081575, 460.7332071745943, 98.740...  \n",
       "9  [166.73200216875014, 459.76336625659087, 99.14...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble features\n",
    "va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "feat_data = va.transform(feat_data).select('machineID','dt_truncated','label_e','features')\n",
    "\n",
    "# set maxCategories so features with > 10 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=10).fit(feat_data)\n",
    "\n",
    "# fit on whole dataset to include all labels in index\n",
    "labelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(feat_data)\n",
    "\n",
    "# split the data into train/test based on date\n",
    "split_date = \"2015-10-30\"\n",
    "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
    "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
    "\n",
    "print(training.count())\n",
    "print(testing.count())\n",
    "training.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample majority class, do we really need this?\n",
    "# SampleBy returns a stratified sample without replacement based on the fraction given on each stratum\n",
    "train_downsampled = training.sampleBy('label', fractions={0.0: 0.135, 1.0: 1.0}, seed=123).cache()\n",
    "train_downsampled.groupby('label').count().show()\n",
    "\n",
    "testing.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache results\n",
    "# cache datasets in memory\n",
    "train_downsampled.cache()\n",
    "testing.cache()\n",
    "\n",
    "# check the number of devices in training and testing data\n",
    "print(train_downsampled.select('deviceid').distinct().count())\n",
    "print(testing.select('deviceid').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-forward",
   "metadata": {},
   "source": [
    "# GBT Gradient-Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pursuant-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('machineID', 'string'),\n",
       " ('dt_truncated', 'timestamp'),\n",
       " ('label_e', 'double'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBTClassifier currently only supports binary classification.\n",
    "training.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol='label_e', featuresCol='features', maxDepth=10, minInstancesPerNode=5, maxIter=50)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline_gbt = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model. This also runs the indexers.\n",
    "model_gbt = pipeline_gbt.fit(training)\n",
    "\n",
    "# save model\n",
    "datestamp = unicode(datetime.datetime.now()).replace(' ','').replace(':','_');\n",
    "gbt_fileName = '../checkpoints/GradientBoostedTree_' + datestamp;\n",
    "gbtDirfilename = modelDir + gbt_fileName;\n",
    "model_gbt.save(gbtDirfilename)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_gbt = model_gbt.transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-gasoline",
   "metadata": {},
   "source": [
    "# XGB eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://repo1.maven.org/maven2/com/nvidia/xgboost4j_3.0/1.0.0-0.1.0/xgboost4j_3.0-1.0.0-0.1.0.jar\n",
    "#!wget https://repo1.maven.org/maven2/com/nvidia/xgboost4j-spark_3.0/1.0.0-0.1.0/xgboost4j-spark_3.0-1.0.0-0.1.0.jar\n",
    "#!wget http://insecure.repo1.maven.org/maven2/com/nvidia/rapids-4-spark_2.12/0.1.0/rapids-4-spark_2.12-0.1.0.jar\n",
    "#!wget https://repo1.maven.org/maven2/ai/rapids/cudf/0.18/cudf-0.18-cuda10-1.jar --no-check-certificate\n",
    "\n",
    "#!wget https://raw.githubusercontent.com/srivatsan88/YoutubeLI/master/dataset/covtype_train.parquet\n",
    "#!wget https://raw.githubusercontent.com/srivatsan88/YoutubeLI/master/dataset/covtype_test.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compliant-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"xgboost4j-spark_3.0-1.0.0-0.1.0.jar\")\n",
    "spark.sparkContext.addPyFile(\"rapids-4-spark_2.12-0.1.0.jar\")\n",
    "\n",
    "from ml.dmlc.xgboost4j.scala.spark import XGBoostClassificationModel, XGBoostClassifier\n",
    "#training.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "palestinian-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoostClassifier_6d72fffbfc9d"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting parameters. you can find these parameters in the link above.\n",
    "params = {'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "          'treeMethod': 'gpu_hist', 'maxDepth': 3, \n",
    "          'growPolicy': 'depthwise', 'lambda_': 1.0,\n",
    "          'subsample': 1.0, 'numRound': 1000,\n",
    "          'numWorkers': 1, 'verbosity': 1}\n",
    "\n",
    "features = [feat for feat in feat_data.columns if feat != 'label_e']\n",
    "\n",
    "# create XGBoost model object\n",
    "# xgboost = XGBoostClassifier()\\\n",
    "#             .setLabelCol('label_e')\\\n",
    "#             .setFeaturesCols(features)\n",
    "\n",
    "xgboost = XGBoostClassifier(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label_e\", \n",
    ")\n",
    "xgboost.setMissing(0.0)\n",
    "\n",
    "# # getting the feature names\n",
    "# target = 'label_e'\n",
    "# features = [feat for feat in feat_data.columns if feat != target]\n",
    "\n",
    "# # setting parameters. you can find these parameters in the link above.\n",
    "# params = {'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "#           'treeMethod': 'gpu_hist', 'maxDepth': 3, \n",
    "#           'growPolicy': 'depthwise', 'lambda_': 1.0,\n",
    "#           'subsample': 1.0, 'numRound': 1000,\n",
    "#           'numWorkers': 1, 'verbosity': 1}\n",
    "\n",
    "# # create XGBoost model object\n",
    "# xgboost = XGBoostClassifier(**params)\\\n",
    "#             .setLabelCol(target)\\\n",
    "#             .setFeaturesCols(features)\n",
    "\n",
    "# xgboost.setMaxDepth(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = xgboost.fit(training)\n",
    "\n",
    "print(\"Training Time: %s seconds\" % (str(time.time() - start_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-modern",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"xgboost4j-spark-0.90.jar\")\n",
    "spark.sparkContext.addPyFile(\"sparkxgb.zip\")\n",
    "\n",
    "from sparkxgb import XGBoostClassifier\n",
    "\n",
    "\n",
    "# loading data\n",
    "reader = spark.read\n",
    "train_data = reader.parquet(\"covtype_train.parquet\")\n",
    "test_data = reader.parquet(\"covtype_test.parquet\")\n",
    "\n",
    "# getting the feature names\n",
    "target = 'target'\n",
    "features = [feat for feat in train_data.schema.names if feat != target]\n",
    "\n",
    "# CPU\n",
    "def vectorize(data_frame):\n",
    "    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\n",
    "    return (VectorAssembler()\n",
    "        .setInputCols(features)\n",
    "        .setOutputCol('features')\n",
    "        .transform(data_frame.select(to_floats))\n",
    "        .select(col('features'), col('target')))\n",
    "\n",
    "train_data = vectorize(train_data)\n",
    "\n",
    "# setting parameters. you can find these parameters in the link above.\n",
    "params = { \n",
    "    'eta': 0.1, 'gamma': 0.1, 'missing': 0.0,\n",
    "    'treeMethod': 'hist', 'maxDepth': 10, \n",
    "    'maxLeaves': 256, 'growPolicy': 'depthwise',\n",
    "    'minChildWeight': 30.0, 'lambda_': 1.0,\n",
    "    'scalePosWeight': 2.0, 'subsample': 1.0,\n",
    "    'nthread': 1, 'numWorkers': 1,\n",
    "}\n",
    "\n",
    "# create XGBoost model object\n",
    "xgboost = XGBoostClassifier(**params)\\\n",
    "            .setLabelCol('target')\\\n",
    "            .setFeaturesCol('features')\n",
    "train_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-tournament",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thousand-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "\n",
    "# loading data\n",
    "reader = spark.read\n",
    "train_data = reader.parquet(\"covtype_train.parquet\")\n",
    "test_data = reader.parquet(\"covtype_test.parquet\")\n",
    "\n",
    "# getting the feature names\n",
    "target = 'target'\n",
    "features = [feat for feat in train_data.schema.names if feat != target]\n",
    "\n",
    "# CPU\n",
    "def vectorize(data_frame):\n",
    "    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\n",
    "    return (VectorAssembler()\n",
    "        .setInputCols(features)\n",
    "        .setOutputCol('features')\n",
    "        .transform(data_frame.select(to_floats))\n",
    "        .select(col('features'), col('target')))\n",
    "\n",
    "\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3, n_estimators=100,\n",
    "                            objective='binary:logistic', booster='gbtree',\n",
    "                            n_jobs=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Values:  [0.74 0.75]\n",
      "Average Accuracy:  0.7448269185258493\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "#model = xgboost.fit(train_data)\n",
    "data = train_data.toPandas()\n",
    "X = data.iloc[:,:-1] # Feature matrix in pd.DataFrame format\n",
    "y = data.iloc[:,-1] # Target vector in pd.Series format\n",
    "\n",
    "acc_scores = cross_val_score(xgb_clf, X, y,\n",
    "                         scoring=\"accuracy\",\n",
    "                         cv=2, n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy Values: \", np.round(acc_scores, 2))\n",
    "print(\"Average Accuracy: \", np.mean(acc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "found-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 1127|\n",
      "|    3|  836|\n",
      "|    4| 1256|\n",
      "|    2| 1535|\n",
      "|    0| 5521|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  210|\n",
      "|    3|  164|\n",
      "|    4|  217|\n",
      "|    2|  327|\n",
      "|    0|11790|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "\n",
    "split_date = \"2015-10-30\"\n",
    "feat_data = feat_data.withColumnRenamed(\"label_e\", \"label\")\n",
    "feat_data = feat_data.withColumn(\"machineID\", feat_data.machineID.cast(IntegerType()))\n",
    "feat_data = feat_data.withColumn(\"label\", feat_data.label.cast(IntegerType()))\n",
    "feat_data = feat_data.withColumn(\"model\", substring(\"model\", 6,1).cast(IntegerType()))\n",
    "\n",
    "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
    "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
    "train_data = training.drop(*['dt_truncated', 'model_encoded']) #model???\n",
    "test_data = testing.drop(*['dt_truncated', 'model_encoded'])\n",
    "\n",
    "train_data = train_data.sampleBy('label', fractions={0: 0.1, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}, seed=0).cache()\n",
    "train_data.groupby('label').count().show()\n",
    "test_data.groupby('label').count().show()\n",
    "\n",
    "# train_data.dtypes\n",
    "# print(train_data.count())\n",
    "# print(test_data.count())\n",
    "# train_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train_data.toPandas()\n",
    "test_ = test_data.toPandas()\n",
    "\n",
    "X_train = train_.iloc[:,:-1]\n",
    "y_train = train_.iloc[:,-1]\n",
    "X_test = test_.iloc[:,:-1]\n",
    "y_test = test_.iloc[:,-1]\n",
    "\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=40, n_estimators=200, grow_policy='lossguide',\n",
    "                            objective='multi:softmax', booster='gbtree', num_classes=5,\n",
    "                            eta=0.5, reg_lambda=0.5, n_jobs=2, random_state=1)\n",
    "\n",
    "model = xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = xgb_clf.predict(dtest)\n",
    "# Predictions returns as probabilities\n",
    "# y_pred = [round(value) for value in preds]\n",
    "# Predictions returns as classes\n",
    "# y_pred = np.array(y_pred).astype(int) \n",
    "y_pred = model.predict(X_test) \n",
    "y_true = y_test # True values, dataframe format\n",
    "\n",
    "print(\"Accuracy: \", np.round(accuracy_score(y_true, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = y_pred.tolist()\n",
    "prediction = testing.repartition(1).withColumn('prediction', \n",
    "    F.udf(lambda x: l[x])(F.monotonically_increasing_id()))\n",
    "prediction.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-liberty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "bigdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
